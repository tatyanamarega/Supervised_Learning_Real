# Supervised Learning: Quality Model Prediction

## Описание проекта
Прогнозная модель для выявления клиентов интернет-магазина "В один клик" с высокой вероятностью снижения покупательской активности.

## Постановка задачи
**Проблема**: До 30% постоянных клиентов снижают активность без явных причин.  
**Решение**: ML-модель для прогнозирования риска снижения активности и сегментации клиентской базы.

## Цель: предсказать вероятность снижения активности клиентов и выделить целевые сегменты для маркетинговых кампаний.

## Ключевые результаты проекта
| Метрики              | До оптимизации     | После оптимизации  |
|----------------------|--------------------|--------------------|
| Test Accuracy        | 0.87               | 0.908 (+3.8%)      |
| Train Accuracy       | 0.92               | 0.954              |
| F1-score             | 0.84               | 0.88               |

## Структура проекта
- `data/` - исходные данные
- `notebooks/` - Jupyter notebook с анализом
- `docs/` - документация

## Структура папок проекта

Supervised_Learning_Real:
- ├── data/
- │   ├── raw/                 # Исходные данные
- │   ├── market_file.csv
- │   ├── market_money.csv
- │   ├── market_time.csv
- │   └── money.csv
- │   └── processed/           # Обработанные данные
- ├── notebooks/               # Jupyter notebooks
- │   └── Supervised_Learning_Real.ipynb
- │   ├── 01_EDA.ipynb # Анализ данных
- │   ├── 02_Modeling.ipynb # Построение моделей
- │   └── 03_Segmentation.ipynb # Сегментация клиентов
- ├── models/ # Сохраненные модели
- ├── docs/                    # Документация, отчеты
- ├── README.md                # Описание проекта
- └── .gitignore               # Исключения ненужных файлов
- └── requirements.txt         # Зависимости 

## Model Comparison
| Model                | Accuracy  | Лучшие параметры                    |
|----------------------|-----------|-------------------------------------|
| RandomForest         | 0.8923    | n_estimators=500, max_depth=20      |
| LogisticRegression   | 0.8860    | C=0.01, solver=lbfgs                |
| SVM                  | 0.8891    | C=0.1, kernel=rbf                   |
| GradientBoosting     | 0.8849    | n_estimators=100, learning_rate=0.2 |

## Выводы
- RandomForest показал наилучший результат после настройки гиперпараметров
- Добавление GradientBoosting расширило сравнительный анализ

## Ключевые инсайты
### Топ-5 значимых признаков:
1. Текущая выручка (SHAP value: 0.42)
2. Активность в маркетинговых кампаниях (0.38)
3. Количество просмотров категорий (0.35)
4. Предыдущая выручка (0.32)
5. Неоплаченные товары (0.28)

### Клиентские сегменты:
    High Risk/High Value: 12% клиентов, 45% выручки,
    High Risk/Low Value: 23% клиентов, 15% выручки,
    Low Risk/High Value: 18% клиентов, 30% выручки.

## История изменений
### Коммит 1: Исходная версия проекта

## Запуск проекта
1. Клонирован репозиторий
2. Установлены зависимости: `pip install -r requirements.txt`
3. Открыт Jupyter notebook: `jupyter notebook notebooks/Supervised_Learning_Real.ipynb`

## Использованные модели
1. **RandomForestClassifier** (Accuracy: 0.87)
2. **LogisticRegression** (Accuracy: 0.85)  
3. **KNeighborsClassifier** (Accuracy: 0.82)

### Коммит 2: Оптимизация RandomForest
- Добавлен RandomForest с оптимизированными параметрами:
  n_estimators=200,      # Увеличили количество деревьев с дефолтных 100 до 200
  max_depth=10,          # Ограничили глубину деревьев
  min_samples_split=5,   # Минимальное число samples для разделения узла
  random_state=RANDOM_STATE

После оптимизации гиперпараметров модели RandomForestClassifier достигнуты следующие метрики:

- **Accuracy на тренировочной выборке:** 0.954 (+8.4% к baseline 0.87)
- **Accuracy на тестовой выборке:** 0.908 (+3.8% к baseline 0.87)

### Ключевые улучшения:
1. Увеличение количества деревьев до 200 (`n_estimators=200`)
2. Ограничение глубины деревьев (`max_depth=10`)
3. Установка минимального числа samples для разделения узла (`min_samples_split=5`)

### Модель демонстрирует:
- Высокую точность (90.8% на тестовых данных)
- Умеренный переобучающий эффект (разница 4.6% между train и test accuracy)
- Улучшение на 3.8% по сравнению с baseline-моделью (0.87 → 0.908)

## Результаты
- Лучшая модель: SVM (0.8891)
- Ключевые факторы снижения активности: 
  - Уменьшение времени на сайте
  - Рост неоплаченных товаров
- Сегменты для персонализации:
  - "Премиум-клиенты с падающей активностью"
  - "Акционные покупатели"

## Коммит 3: Оптимизация SHAP анализа
- Реализован анализ важности признаков с SHAP
- Добавлена сегментация клиентов по:
  - Вероятности снижения активности
  - Совокупной выручке за 3 месяца
- Улучшена визуализация результатов

## Маркетинговые рекомендации

## Персонализированные предложения
1. **Целевой VIP с риском ухода**:
   - Эксклюзивные ранние доступы к новинкам за 48 часов до всех
   - Персональный менеджер

2. **Акционные покупатели**:
   - Персональные купоны на часто покупаемые категории
   - Программа лояльности: кэшбэк 5-15% на следующий заказ
   - Персонализированные бандлы
   
## Развитие проекта
- Интеграция с CRM-системой
- A/B тестирование рекомендаций
- Модель LTV для прогноза пожизненной ценности

## Автор
Ф.И.: [Марега Татьяна]
Контакты: [me@marega.ru]
Дата: [22.04.2025]